{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Use Deep Learning to Clone Driving Behavior\n",
    "\n",
    "Overview\n",
    "-----\n",
    "This repository is for the third project of Udacity Self Driving Car, Driving Behavior Clone. In general, we will train a deep neural network to predict for the steering angle of the car given the center image within a video stream. For the training data, Udacity provides an excellent simulator, in which we can collect data for training and test our learned models.\n",
    "\n",
    "This `project` is based on python and keras framework. \n",
    "\n",
    "Bried summary of this repository:\n",
    "* `README.md` : document of this repository\n",
    "* model.h5 : store the final model for test, contains the structure and weights of the network trained\n",
    "* drive.py : load stored model and send prediction to simulator\n",
    "* video.py : create a video of images within one directory\n",
    "* model.py : contains the model structure and training code\n",
    "* reader.py : contains the class and preprocessing of input images\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/center_origin.png \"Original Center Image\"\n",
    "[image2]: ./examples/left_origin.png \"Original Left Image\"\n",
    "[image3]: ./examples/right_origin.png \"Original right Image\"\n",
    "[image4]: ./examples/placeholder.png \"Grayscaling\"\n",
    "[image5]: ./examples/placeholder_small.png \"Recovery Image\"\n",
    "[image6]: ./examples/placeholder_small.png \"Recovery Image\"\n",
    "[image7]: ./examples/placeholder_small.png \"Recovery Image\"\n",
    "[image8]: ./examples/placeholder_small.png \"Normal Image\"\n",
    "[image9]: ./examples/placeholder_small.png \"Flipped Image\"\n",
    "\n",
    "### Dependencies\n",
    "This lab requires:\n",
    "\n",
    "* [CarND Term1 Starter Kit](https://github.com/udacity/CarND-Term1-Starter-Kit)\n",
    "\n",
    "The lab enviroment can be created with CarND Term1 Starter Kit. Click [here](https://github.com/udacity/CarND-Term1-Starter-Kit/blob/master/README.md) for the details.\n",
    "\n",
    "### Usage\n",
    "For traing model, you need to create a directory, you can name it as 'data', which contains a driving log file and a directory contains all the images.\n",
    "following command:\n",
    "```sh\n",
    "model.save(filepath)\n",
    "```\n",
    "\n",
    "For testing model, you can use the model here, model.h5, and use the drive.py provided by Udacity to test for real time simulation, also you need the simulator turned on.\n",
    "```sh\n",
    "python drive.py model.h5 run1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing Strategy\n",
    "For behavioral cloning task, data plays an essential rule that it can directly influence the result of out model. First, we must ensure that the label for each data is correct, only in this way can the network learns something useful. For this particular project, it is natural to treat it as a regression problem (we may also transfer it to a classification problem). The data is a 2D RGB image, the label for that image data is the steering angle at the same timestamp. But, usually it is very hard to collect smooth steering angles because of the data collecting process, so one thing we can do to alleviate this is to do exponential smoothing for the training steer angles.\n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "There a lot of thing we can do to deal with the input images. The original image shape is 320x160, but not all of them are useful for this project, we can safely drop the upper part of the image because for predicting steer angles, we are actually look at the lane and board of the road, the upper part usually contains sky and other noisy information, which are harmful for the training. The image after croppedis of size 50x\n",
    "\n",
    "birhgtness, contrast\n",
    "\n",
    "flip\n",
    "\n",
    "shift\n",
    "\n",
    "resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "____________________________________________________________________________________________________\n",
    "Layer (type)                     Output Shape          Param #     Connected to                     \n",
    "====================================================================================================\n",
    "image (InputLayer)               (None, 66, 200, 3)    0                                            \n",
    "____________________________________________________________________________________________________\n",
    "color_layer (Convolution2D)      (None, 66, 200, 3)    12          image[0][0]                      \n",
    "____________________________________________________________________________________________________\n",
    "conv2 (Convolution2D)            (None, 31, 98, 24)    1824        color_layer[0][0]                \n",
    "____________________________________________________________________________________________________\n",
    "conv3 (Convolution2D)            (None, 14, 47, 36)    21636       conv2[0][0]                      \n",
    "____________________________________________________________________________________________________\n",
    "conv4 (Convolution2D)            (None, 5, 22, 48)     43248       conv3[0][0]                      \n",
    "____________________________________________________________________________________________________\n",
    "conv5 (Convolution2D)            (None, 3, 20, 64)     27712       conv4[0][0]                      \n",
    "____________________________________________________________________________________________________\n",
    "conv6 (Convolution2D)            (None, 1, 18, 64)     36928       conv5[0][0]                      \n",
    "____________________________________________________________________________________________________\n",
    "flatten_1 (Flatten)              (None, 1152)          0           conv6[0][0]                      \n",
    "____________________________________________________________________________________________________\n",
    "dense_1 (Dense)                  (None, 100)           115300      flatten_1[0][0]                  \n",
    "____________________________________________________________________________________________________\n",
    "dropout_2 (Dropout)              (None, 100)           0           dense_1[0][0]                    \n",
    "____________________________________________________________________________________________________\n",
    "dense_2 (Dense)                  (None, 50)            5050        dropout_2[0][0]                  \n",
    "____________________________________________________________________________________________________\n",
    "dropout_3 (Dropout)              (None, 50)            0           dense_2[0][0]                    \n",
    "____________________________________________________________________________________________________\n",
    "dense_3 (Dense)                  (None, 10)            510         dropout_3[0][0]                  \n",
    "____________________________________________________________________________________________________\n",
    "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
    "====================================================================================================\n",
    "Total params: 252,231\n",
    "Trainable params: 252,231\n",
    "Non-trainable params: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
